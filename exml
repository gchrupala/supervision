# Explainable ML and analysis methods for neural networks

## Description
Machine learning in general and neural network models in particular are being used in an increasingly wide variety of domains, impacting society in deep but often poorly understood ways. As such, interest in developing methods which allow us to better understand these models has been growing. Among others, the following research problems have been addressed:

- Probing neural activation patterns to find out what information they decode (aka diagnostic classifiers)
- Visualizing input features influencing model decisions
- Modifying neural architectures to make them more interpretable
- Applying neural models to synthetic data to understand their performance in simplified settings

## Requirements: Solid Python programming skills and familiarity with machine learning and neural networks specifically. 
For this project you will need to find a concrete topic related to one or more of the points listed above, and explore it experimentally on datasets of your choice. Especially welcome are topics related to processing natural language or speech. 

## References:

- Matthew D Zeiler & Rob Fergus (2014). Visualizing and understanding convolutional networks. In European Conference on Computer Vision (pp. 818-833). https://arxiv.org/pdf/1311.2901
- Yonatan Belinkov, & James Glass (2018). Analysis Methods in Neural Language Processing: A Survey. arXiv preprint arXiv:1812.08951. https://arxiv.org/abs/1812.08951
- Afra Alishahi, Grzegorz Chrupala, & Tal Linzen (2019). Analyzing and Interpreting Neural Networks for NLP: A Report on the First BlackboxNLP Workshop. Natural Language Engineering, 25(4), 543-557. http://dx.doi.org/10.1017/S135132491900024X, preprint: https://arxiv.org/abs/1904.04063 
- Grzegorz Chrupała & Afra Alishahi (2019). Correlating neural and symbolic representations of language. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. https://www.aclweb.org/anthology/P19-1283/
- Afra Alishahi, Marie Barking and Grzegorz Chrupała (2017). Encoding of phonology in a recurrent neural model of grounded speech. CoNLL. https://aclanthology.info/papers/K17-1037/k17-1037
- Grzegorz Chrupała, Lieke Gelderloos and Afra Alishahi (2017). Representations of language in a model of visually grounded speech signal. ACL. https://aclanthology.info/papers/P17-1057/p17-1057
- Ákos Kádár, Grzegorz Chrupała and Afra Alishahi (2017). Representation of linguistic form and function in recurrent neural networks. Computational Linguistics, 43(4):761-780. https://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00300
